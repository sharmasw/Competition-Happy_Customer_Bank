{"nbformat": 4, "cells": [{"execution_count": 610, "source": "import pandas as pd\nimport datetime as dt\nimport numpy as np\nimport scipy.stats as stats\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import ensemble\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn import cross_validation\nfrom sklearn import preprocessing\npath='D:/Project Data/Happy_Customer_Bank/'\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(color_codes=True)\n%matplotlib inline\nimport math", "cell_type": "code", "metadata": {"collapsed": true, "trusted": true}, "outputs": []}, {"execution_count": 611, "source": "train=pd.read_csv(path+'Train_nyOWmfK.csv',encoding='iso-8859-1')\ntestdata=pd.read_csv(path+'Test_bCtAN1w.csv',encoding='iso-8859-1')\ntrain.ix[train['Gender']=='Female','Gender_']=1\ntrain.ix[train['Gender']=='Male','Gender_']=0\ntrain.ix[train['Mobile_Verified']=='N','Mobile_Verified_']=0\ntrain.ix[train['Mobile_Verified']=='Y','Mobile_Verified_']=1\ntrain.ix[train['Filled_Form']=='Y','Filled_Form_']=1\ntrain.ix[train['Filled_Form']=='N','Filled_Form_']=0\ntrain.ix[train['Device_Type']=='Mobile','Device_Type_']=0\ntrain.ix[train['Device_Type']=='Web-browser','Device_Type_']=1\n\ntrain['age']=[(2015-(1900+int(i[-2:]))) for i in train['DOB'].values]  \n\ntrain['Loan_Amount_Applied']=train['Loan_Amount_Applied'].fillna(train['Loan_Amount_Applied'].mean())\n\ntrain['Loan_Tenure_Applied']=train['Loan_Tenure_Applied'].fillna(train['Loan_Tenure_Applied'].median())\n\ntrain['Existing_EMI']=train['Existing_EMI'].fillna(0)\n\ntrain['Loan_Amount_Submitted']=train['Loan_Amount_Submitted'].fillna(train['Loan_Amount_Submitted'].mean())\n\ntrain['Loan_Tenure_Submitted']=train['Loan_Tenure_Submitted'].fillna(train['Loan_Tenure_Submitted'].median())\n\ntrain['Interest_Rate']=train['Interest_Rate'].fillna(train['Interest_Rate'].median())\n\ntrain['Processing_Fee']=train['Processing_Fee'].fillna(train['Processing_Fee'].mean())\n\ntrain['EMI_Loan_Submitted']=train['EMI_Loan_Submitted'].fillna(train['EMI_Loan_Submitted'].mean())\n\nLoan_Amount_Applied_mean=train['Loan_Amount_Applied'].mean()\n\nLoan_Tenure_Applied_median=train['Loan_Tenure_Applied'].median()\n\nLoan_Amount_Submitted_mean=train['Loan_Amount_Submitted'].mean()\n\nLoan_Tenure_Submitted_median=train['Loan_Tenure_Submitted'].median()\n\nInterest_Rate_median=train['Interest_Rate'].median()\n\nProcessing_Fee_mean=train['Processing_Fee'].mean()\n\nEMI_Loan_Submitted_mean=train['EMI_Loan_Submitted'].mean()", "cell_type": "code", "metadata": {"collapsed": true, "trusted": true}, "outputs": []}, {"execution_count": 612, "source": "print(np.unique(train['Source']))\n\nprint(np.unique(train['Var1']))", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "['Other' 'S122' 'S127' 'S133' 'S134' 'S137' 'S143' 'S159' 'S161']\n['HAXB' 'HAXF' 'HAZD' 'HBXA' 'HBXB' 'HBXX' 'HCXF']\n", "output_type": "stream", "name": "stdout"}]}, {"execution_count": 613, "source": "print(train.shape)\ntrain=train[(train['age'] < 60) | (train['Disbursed'] >=1)]\ntrain=train[(train['Interest_Rate'] < 30) | (train['Disbursed'] >=1) ]\ntrain=train[(train['Loan_Tenure_Applied'] > 1) | (train['Disbursed'] >=1) ]\ntrain=train[(train['Monthly_Income'] < 600000) | (train['Monthly_Income'] > 6000)]\ntrain=train[(train['Existing_EMI'] <= 0) | (train['Existing_EMI'] >= 1000) | (train['Disbursed'] >=1) ]\nprint(train.shape)\nnp.unique(train['Disbursed'],return_counts=True)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "(70671, 31)\n(38019, 31)\n", "output_type": "stream", "name": "stdout"}, {"execution_count": 613, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "(array([0, 1], dtype=int64), array([36777,  1242], dtype=int64))"}}]}, {"execution_count": 614, "source": "train.corr()['Disbursed'].order(ascending=False)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"execution_count": 614, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "Disbursed                1.000000\nLoggedIn                 0.801020\nVar5                     0.123644\nFilled_Form_             0.093556\nEMI_Loan_Submitted       0.083339\nMobile_Verified_         0.082513\nLoan_Amount_Submitted    0.076521\nProcessing_Fee           0.057081\nage                      0.044139\nExisting_EMI             0.011611\nMonthly_Income           0.004627\nLoan_Tenure_Submitted    0.003144\nVar4                    -0.008858\nLoan_Amount_Applied     -0.017654\nGender_                 -0.083118\nInterest_Rate           -0.102902\nLoan_Tenure_Applied     -0.146883\nDevice_Type_            -0.428315\nName: Disbursed, dtype: float64"}}]}, {"execution_count": 615, "source": "Cat_Var=['Var4','Source','Var2','Var1']\nNum_Var=['Monthly_Income',\n    #'Loan_Amount_Applied',\n    #'Existing_EMI',\n    'Var5',\n         #'Loan_Amount_Submitted',\n    #'Loan_Tenure_Submitted',\n     # 'Interest_Rate',\n    #'Processing_Fee',\n    #'EMI_Loan_Submitted'\n        ]\nProcessed_Var=['Gender_',\n    'Mobile_Verified_','Filled_Form_',\n    'Device_Type_',\n    'age']\nTarget_log=['LoggedIn']\nTarget=['Disbursed']", "cell_type": "code", "metadata": {"collapsed": true, "trusted": true}, "outputs": []}, {"execution_count": 616, "source": "Num_Var_log=Num_Var +['LoggedIn']", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": []}, {"execution_count": 617, "source": "cat_column=['Var4']\ncat_data=train['Var4'].tolist() +testdata['Var4'].tolist()\ndata_=train[cat_column]\nle = preprocessing.LabelEncoder()\nle.fit(cat_data)\nnewcol=le.transform(data_)\nenc = OneHotEncoder(sparse=False)\nenc.fit(newcol)\nprint(enc.n_values_)\nprint(enc.feature_indices_)\ndummy_var4=enc.transform(newcol)\n\ncat_column=['Source']\ncat_data=train['Source'].tolist() +testdata['Source'].tolist()\ndata_=train[cat_column]\nle1 = preprocessing.LabelEncoder()\nle1.fit(cat_data)\nnewcol=le1.transform(data_)\nenc1 = OneHotEncoder(sparse=False)\nenc1.fit(newcol)\nprint(enc1.n_values_)\nprint(enc1.feature_indices_)\ndummy_Source=enc1.transform(newcol)\n\n\ncat_column=['Var2']\ncat_data=train['Var2'].tolist() +testdata['Var2'].tolist()\ndata_=train[cat_column]\nle2 = preprocessing.LabelEncoder()\nle2.fit(cat_data)\nnewcol=le2.transform(data_)\nenc2 = OneHotEncoder(sparse=False)\nenc2.fit(newcol)\nprint(enc2.n_values_)\nprint(enc2.feature_indices_)\ndummy_var2=enc2.transform(newcol)\n\ncat_column=['Var1']\ncat_data=train['Var1'].tolist() +testdata['Var1'].tolist()\ndata_=train[cat_column]\nle3 = preprocessing.LabelEncoder()\nle3.fit(cat_data)\nnewcol=le3.transform(data_)\nenc3 = OneHotEncoder(sparse=False)\nenc3.fit(newcol)\nprint(enc3.n_values_)\nprint(enc3.feature_indices_)\ndummy_var1=enc3.transform(newcol)", "cell_type": "code", "metadata": {"scrolled": true, "collapsed": false, "trusted": true}, "outputs": [{"text": "[3]\n[0 3]\n[13]\n[ 0 13]\n[7]\n[0 7]\n[7]\n[0 7]\n", "output_type": "stream", "name": "stdout"}]}, {"execution_count": 618, "source": "#dummy=np.hstack((dummy_var4,dummy_Source,dummy_var2,dummy_var1))\ndummy=np.hstack((dummy_var4,dummy_Source,dummy_var2))\nprint(dummy.shape)\n\nNum_variable=Num_Var+Processed_Var\n\ntrain_num=train[Num_variable].as_matrix()\ntraindata=np.hstack((train_num,dummy))\ntraindata.shape", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "(38019, 19)\n", "output_type": "stream", "name": "stdout"}, {"execution_count": 618, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "(38019, 26)"}}]}, {"execution_count": 619, "source": "from sklearn.cross_validation import StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(train[Target_log], 2, test_size=.99, random_state=42)\nfor train_index, test_index in sss:\n    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train_s, X_test_s = traindata[train_index], traindata[test_index]\n    y_train_s, y_test_s = train[Target_log].values[train_index], train[Target_log].values[test_index]\n\nX_train_s.shape, X_test_s.shape, y_train_s.shape, y_test_s.shape\n\ny_test_s=[i[0] for i in y_test_s]", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": []}, {"source": "# predicting login", "cell_type": "markdown", "metadata": {}}, {"execution_count": 620, "source": "\nrfc = ensemble.RandomForestClassifier()\nrfc.fit(X_train_s,y_train_s)\npredict_class=rfc.predict(X_test_s)\nprint(accuracy_score(predict_class, y_test_s))\nconfusion_matrix(predict_class, y_test_s)\n#metrics.auc(predict_class, target_test_1)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "0.952310103882\n", "output_type": "stream", "name": "stdout"}, {"text": "C:\\Anaconda3\\lib\\site-packages\\IPython\\kernel\\__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  app.launch_new_instance()\n", "output_type": "stream", "name": "stderr"}, {"execution_count": 620, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[35606,  1644],\n       [  151,   238]])"}}]}, {"execution_count": 621, "source": "logistic = linear_model.LogisticRegression()\nlogistic.fit(X_train_s,y_train_s)\npredict_class=logistic.predict(X_test_s)\nprint(accuracy_score(predict_class, y_test_s))\nconfusion_matrix(predict_class, y_test_s)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "0.949998671591\n", "output_type": "stream", "name": "stdout"}, {"text": "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:125: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n", "output_type": "stream", "name": "stderr"}, {"execution_count": 621, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[35757,  1882],\n       [    0,     0]])"}}]}, {"execution_count": 622, "source": "bag=ensemble.BaggingClassifier(rfc)\nbag.fit(X_train_s,y_train_s)\npredict_class2=bag.predict(X_test_s)\nprint(accuracy_score(predict_class2, y_test_s))\nconfusion_matrix(predict_class2, y_test_s)\n", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "0.955604559101\n", "output_type": "stream", "name": "stdout"}, {"text": "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:493: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n", "output_type": "stream", "name": "stderr"}, {"execution_count": 622, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[35744,  1658],\n       [   13,   224]])"}}]}, {"execution_count": 623, "source": "bag_=ensemble.BaggingClassifier(logistic)\nbag_.fit(X_train_s,y_train_s)\npredict_class2=bag_.predict(X_test_s)\nprint(accuracy_score(predict_class2, y_test_s))\nconfusion_matrix(predict_class2, y_test_s)\n", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "0.949493876033\n", "output_type": "stream", "name": "stdout"}, {"text": "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:493: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n", "output_type": "stream", "name": "stderr"}, {"execution_count": 623, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[35737,  1881],\n       [   20,     1]])"}}]}, {"source": "# predicting disb", "cell_type": "markdown", "metadata": {}}, {"execution_count": 624, "source": "Numerical_var= Num_Var_log+Processed_Var\n\ntrain_log=train[Numerical_var].as_matrix()\ntraindata_log=np.hstack((train_log,dummy))\ntraindata_log.shape", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"execution_count": 624, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "(38019, 27)"}}]}, {"execution_count": 625, "source": "sss1 = StratifiedShuffleSplit(train[Target], 2, test_size=.99, random_state=42)\nfor train_index1, test_index1 in sss1:\n    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train_log, X_test_log = traindata_log[train_index1], traindata_log[test_index1]\n    y_train_log, y_test_log = train[Target].values[train_index1], train[Target].values[test_index1]", "cell_type": "code", "metadata": {"collapsed": true, "trusted": true}, "outputs": []}, {"execution_count": 626, "source": "rfc_ = ensemble.RandomForestClassifier()\nrfc_.fit(X_train_log,y_train_log)\npredict_log=rfc_.predict(X_test_log)\nprint(accuracy_score(predict_log, y_test_log))\nconfusion_matrix(predict_log, y_test_log)", "cell_type": "code", "metadata": {"scrolled": true, "collapsed": false, "trusted": true}, "outputs": [{"text": "0.978479768325\n", "output_type": "stream", "name": "stdout"}, {"text": "C:\\Anaconda3\\lib\\site-packages\\IPython\\kernel\\__main__.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  from IPython.kernel.zmq import kernelapp as app\n", "output_type": "stream", "name": "stderr"}, {"execution_count": 626, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[36137,   538],\n       [  272,   692]])"}}]}, {"execution_count": 627, "source": "logistic1 = linear_model.LogisticRegression()\nlogistic1.fit(X_train_log,y_train_log)\npredict_log=logistic1.predict(X_test_log)\nprint(accuracy_score(predict_log, y_test_log))\nconfusion_matrix(predict_log, y_test_log)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "0.966550652249\n", "output_type": "stream", "name": "stdout"}, {"text": "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:125: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n", "output_type": "stream", "name": "stderr"}, {"execution_count": 627, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[36380,  1230],\n       [   29,     0]])"}}]}, {"execution_count": 628, "source": "bag2=ensemble.BaggingClassifier(rfc_)\nbag2.fit(X_train_log,y_train_log)\npredict_log_=bag2.predict(X_test_log)\nprint(accuracy_score(predict_log_, y_test_log))\nconfusion_matrix(predict_log_, y_test_log)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "0.980472382369\n", "output_type": "stream", "name": "stdout"}, {"text": "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:493: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n", "output_type": "stream", "name": "stderr"}, {"execution_count": 628, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[36141,   467],\n       [  268,   763]])"}}]}, {"execution_count": 629, "source": "bag2_=ensemble.BaggingClassifier(logistic1)\nbag2_.fit(X_train_log,y_train_log)\npredict_log_=bag2_.predict(X_test_log)\nprint(accuracy_score(predict_log_, y_test_log))\nconfusion_matrix(predict_log_, y_test_log)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "0.966338106751\n", "output_type": "stream", "name": "stdout"}, {"text": "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:493: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n", "output_type": "stream", "name": "stderr"}, {"execution_count": 629, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[36370,  1228],\n       [   39,     2]])"}}]}, {"execution_count": 630, "source": "name='rf-log-bag-rf'", "cell_type": "code", "metadata": {"collapsed": true, "trusted": true}, "outputs": []}, {"source": "# test datset", "cell_type": "markdown", "metadata": {}}, {"execution_count": 631, "source": "testdata.ix[testdata['Gender']=='Female','Gender_']=1\ntestdata.ix[testdata['Gender']=='Male','Gender_']=0\ntestdata.ix[testdata['Mobile_Verified']=='N','Mobile_Verified_']=0\ntestdata.ix[testdata['Mobile_Verified']=='Y','Mobile_Verified_']=1\ntestdata.ix[testdata['Filled_Form']=='Y','Filled_Form_']=1\ntestdata.ix[testdata['Filled_Form']=='N','Filled_Form_']=0\ntestdata.ix[testdata['Device_Type']=='Mobile','Device_Type_']=0\ntestdata.ix[testdata['Device_Type']=='Web-browser','Device_Type_']=1\n\ntestdata['age']=[(2015-(1900+int(i[-2:]))) for i in testdata['DOB'].values]  \n\ntestdata['Loan_Amount_Applied']=testdata['Loan_Amount_Applied'].fillna(Loan_Amount_Applied_mean)\n\ntestdata['Loan_Tenure_Applied']=testdata['Loan_Tenure_Applied'].fillna(Loan_Tenure_Applied_median)\n\ntestdata['Existing_EMI']=testdata['Existing_EMI'].fillna(0)\n\ntestdata['Loan_Amount_Submitted']=testdata['Loan_Amount_Submitted'].fillna(Loan_Amount_Submitted_mean)\n\ntestdata['Loan_Tenure_Submitted']=testdata['Loan_Tenure_Submitted'].fillna(Loan_Tenure_Submitted_median)\n\ntestdata['Interest_Rate']=testdata['Interest_Rate'].fillna(Interest_Rate_median)\n\ntestdata['Processing_Fee']=testdata['Processing_Fee'].fillna(Processing_Fee_mean)\n\ntestdata['EMI_Loan_Submitted']=testdata['EMI_Loan_Submitted'].fillna(EMI_Loan_Submitted_mean)\n", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": []}, {"execution_count": 632, "source": "cat_column=['Var4']\ndata_=testdata[cat_column]\nnewcol=le.transform(data_)\nprint(enc.n_values_)\nprint(enc.feature_indices_)\ndummy_var4_test=enc.transform(newcol)\n\ncat_column=['Source']\ndata_=testdata[cat_column]\nnewcol=le1.transform(data_)\nprint(enc1.n_values_)\nprint(enc1.feature_indices_)\ndummy_Source_test=enc1.transform(newcol)\n\ncat_column=['Var2']\ndata_=testdata[cat_column]\nnewcol=le2.transform(data_)\nprint(enc2.n_values_)\nprint(enc2.feature_indices_)\ndummy_var2_test=enc2.transform(newcol)\n\ncat_column=['Var1']\ndata_=testdata[cat_column]\nnewcol=le3.transform(data_)\nprint(enc3.n_values_)\nprint(enc3.feature_indices_)\ndummy_var1_test=enc3.transform(newcol)\n", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "[3]\n[0 3]\n[13]\n[ 0 13]\n[7]\n[0 7]\n[7]\n[0 7]\n", "output_type": "stream", "name": "stdout"}]}, {"execution_count": 633, "source": "#dummy_test=np.hstack((dummy_var4_test,dummy_Source_test,dummy_var2_test,dummy_var1_test))\ndummy_test=np.hstack((dummy_var4_test,dummy_Source_test,dummy_var2_test))\nprint(dummy_test.shape)\ntestdata_num=testdata[Num_variable].as_matrix()\ntestdata_final=np.hstack((testdata_num,dummy_test))\ntestdata_final.shape", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "(37717, 19)\n", "output_type": "stream", "name": "stdout"}, {"execution_count": 633, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "(37717, 26)"}}]}, {"execution_count": 634, "source": "predict_class_test=logistic.predict(testdata_final)\nnp.unique(predict_class_test, return_counts=True)\npredict_class_test=[[i] for i in predict_class_test]\n\n\npredict_ense_test=rfc.predict(testdata_final)\nnp.unique(predict_ense_test, return_counts=True)\npredict_ense_test=[[i] for i in predict_ense_test]\n\npredict_bag_test=bag.predict(testdata_final)\nnp.unique(predict_bag_test, return_counts=True)\npredict_bag_test=[[i] for i in predict_bag_test]\n\npredict_bag2_test=bag_.predict(testdata_final)\nnp.unique(predict_bag2_test, return_counts=True)\npredict_bag2_test=[[i] for i in predict_bag2_test]", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": []}, {"execution_count": 635, "source": "testdata_full_final=np.hstack((testdata_final,predict_class_test))\ntestdata_full_final.shape\n\npredict_log_test=logistic1.predict(testdata_full_final)\npredict_log_test=predict_log_test.tolist()\nprint(np.unique(predict_log_test,return_counts=True))\nsub=pd.DataFrame(data={'ID':testdata['ID'],'Disbursed':predict_log_test},columns=['ID','Disbursed'])\n#sub.to_csv(path+'sub13.csv',index=False)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "(array([0, 1]), array([29311,  8406], dtype=int64))\n", "output_type": "stream", "name": "stdout"}]}, {"execution_count": 636, "source": "testdata_full_final=np.hstack((testdata_final,predict_ense_test))\ntestdata_full_final.shape\n\npredict_log_test_=rfc_.predict(testdata_full_final)\npredict_log_test_=predict_log_test_.tolist()\nprint(np.unique(predict_log_test_,return_counts=True))\nsub1=pd.DataFrame(data={'ID':testdata['ID'],'Disbursed':predict_log_test_},columns=['ID','Disbursed'])\n#sub1.to_csv(path+'ense_sub13.csv',index=False)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "(array([0, 1]), array([36127,  1590], dtype=int64))\n", "output_type": "stream", "name": "stdout"}]}, {"execution_count": 637, "source": "testdata_full_final=np.hstack((testdata_final,predict_bag_test))\ntestdata_full_final.shape\n\npredict_log_test_1=bag2.predict(testdata_full_final)\npredict_log_test_1=predict_log_test_1.tolist()\nprint(np.unique(predict_log_test_1,return_counts=True))\nsub2=pd.DataFrame(data={'ID':testdata['ID'],'Disbursed':predict_log_test_1},columns=['ID','Disbursed'])\n#sub2.to_csv(path+'bag_sub13.csv',index=False)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "(array([0, 1]), array([37596,   121], dtype=int64))\n", "output_type": "stream", "name": "stdout"}]}, {"execution_count": 638, "source": "testdata_full_final=np.hstack((testdata_final,predict_bag2_test))\ntestdata_full_final.shape\n\npredict_log_test_1=bag2_.predict(testdata_full_final)\npredict_log_test_1=predict_log_test_1.tolist()\nprint(np.unique(predict_log_test_1,return_counts=True))\nsub2_=pd.DataFrame(data={'ID':testdata['ID'],'Disbursed':predict_log_test_1},columns=['ID','Disbursed'])\n#sub2.to_csv(path+'bag_sub13.csv',index=False)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"text": "(array([0, 1]), array([37709,     8], dtype=int64))\n", "output_type": "stream", "name": "stdout"}]}, {"execution_count": 639, "source": "submission=pd.merge(pd.merge(pd.merge(sub,sub1,how='inner', on='ID'),sub2,how='inner', on='ID'),sub2_,how='inner', on='ID')", "cell_type": "code", "metadata": {"scrolled": true, "collapsed": false, "trusted": true}, "outputs": []}, {"execution_count": 644, "source": "submission.columns", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"execution_count": 644, "output_type": "execute_result", "metadata": {}, "data": {"text/plain": "Index(['ID', 'Disbursed_x', 'Disbursed_y', 'Disbursed_x', 'Disbursed_y'], dtype='object')"}}]}, {"execution_count": 646, "source": "submission['max']=submission[['Disbursed_x', 'Disbursed_y', 'Disbursed_x', 'Disbursed_y']].max(axis=1)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": []}, {"execution_count": 647, "source": "submission1=pd.DataFrame(data={'ID': testdata['ID'],'Disbursed':submission['max']},columns=['ID','Disbursed'])\nsubmission1.to_csv(path+name+'.csv',index=False)", "cell_type": "code", "metadata": {"collapsed": true, "trusted": true}, "outputs": []}, {"execution_count": 649, "source": "submission1.head(10)", "cell_type": "code", "metadata": {"collapsed": false, "trusted": true}, "outputs": [{"execution_count": 649, "output_type": "execute_result", "metadata": {}, "data": {"text/html": "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Disbursed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td> ID000026A10</td>\n      <td> 0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td> ID000054C40</td>\n      <td> 0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td> ID000066O10</td>\n      <td> 0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td> ID000110G00</td>\n      <td> 1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td> ID000113J30</td>\n      <td> 0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td> ID000133D30</td>\n      <td> 0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td> ID000156A10</td>\n      <td> 0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td> ID000162G20</td>\n      <td> 0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td> ID000174S40</td>\n      <td> 1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td> ID000175T00</td>\n      <td> 1</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "            ID  Disbursed\n0  ID000026A10          0\n1  ID000054C40          0\n2  ID000066O10          0\n3  ID000110G00          1\n4  ID000113J30          0\n5  ID000133D30          0\n6  ID000156A10          0\n7  ID000162G20          0\n8  ID000174S40          1\n9  ID000175T00          1"}}]}, {"execution_count": null, "source": "", "cell_type": "code", "metadata": {"collapsed": true, "trusted": true}, "outputs": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.4.3", "pygments_lexer": "ipython3", "file_extension": ".py"}}, "nbformat_minor": 0}